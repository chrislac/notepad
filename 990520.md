<p>I have reproduced this scenario in my test environment and I could find my data normally.<br>
To reproduce it I’ve followed these steps.</p>
<p><strong>1 - Installed and configured my NFS Server on my Master Node (Debian Linux, this might change depending on your Linux distribution):</strong></p>
<p>Before installing the NFS Kernel server, we need to update our system’s repository index:</p>
<pre><code>$ sudo apt-get update
</code></pre>
<p>Now, run the following command in order to install the NFS Kernel Server on your system:</p>
<pre><code>$ sudo apt install nfs-kernel-server
</code></pre>
<p>Create the Export Directory</p>
<p><code>$ sudo mkdir -p /mnt/nfs_server_files</code></p>
<p>As we want all clients to access the directory, we will remove restrictive permissions of the export folder through the following commands (this may vary on your set-up according to your security policy):</p>
<pre><code>$ sudo chown nobody:nogroup /mnt/nfs_server_files
$ sudo chmod 777 /mnt/nfs_server_files
</code></pre>
<p>Assign server access to client(s) through NFS export file</p>
<pre><code>$ sudo nano /etc/exports
</code></pre>
<p>Inside this file, add a new line to allow access from other servers to your share.</p>
<pre><code>/mnt/nfs_server_files        10.128.0.0/24(rw,sync,no_subtree_check)
</code></pre>
<p>You may want to use different options in your share. 10.128.0.0/24 is my k8s internal network.</p>
<p>Export the shared directory and restart the service to make sure all configuration files are correct.</p>
<pre><code>$ sudo exportfs -a
$ sudo systemctl restart nfs-kernel-server
</code></pre>
<p>Check all active shares:</p>
<pre><code>$ sudo exportfs
/mnt/nfs_server_files
                10.128.0.0/24
</code></pre>
<p><strong>2 - Install NFS Client on all my Worker Nodes:</strong></p>
<pre><code>$ sudo apt-get update
$ sudo apt-get install nfs-common
</code></pre>
<p>At this point you can make a test to check if you have access to your share from your worker nodes:</p>
<pre><code>$ sudo mkdir -p /mnt/sharedfolder_client
$ sudo mount kubemaster:/mnt/nfs_server_files /mnt/sharedfolder_client
</code></pre>
<p>Notice that at this point you can use the name of your master node. K8s is taking care of the DNS here.<br>
Check if the volume mounted as expected and create some folders and files to male sure everything is working fine.</p>
<pre><code>$ cd /mnt/sharedfolder_client
$ mkdir test
$ touch file
</code></pre>
<p>Go back to your master node and check if these files are at /mnt/nfs_server_files folder.</p>
<p><strong>3 - Install NFS Client Provisioner</strong>.</p>
<p>Create a yaml file with some configurations:</p>
<pre><code>$ more values-nfs-client.yaml 

replicaCount: 2

nfs:
  server: kubemaster
  path: /mnt/sharedfolder_client
  mountOptions:

storageClass:
  archiveOnDelete: false
</code></pre>
<p>Install the provisioner using helm:</p>
<pre><code>$ helm install --name ext --namespace nfs -f values-nfs-client.yaml stable/nfs-client-provisioner
</code></pre>
<p>Notice that I’ve specified a namespace for it.<br>
Check if they are running:</p>
<pre><code>$ kubectl get pods -n nfs
NAME                                         READY   STATUS      RESTARTS   AGE
ext-nfs-client-provisioner-f8964b44c-2876n   1/1     Running     0          84s
ext-nfs-client-provisioner-f8964b44c-8t2jc   1/1     Running     0          84s
</code></pre>
<p>At this point we have a storageclass called nfs-client:</p>
<pre><code>$ kubectl get storageclass -n nfs
NAME         PROVISIONER                                AGE
nfs-client   cluster.local/ext-nfs-client-provisioner   5m30s
</code></pre>
<p>We need to create a PersistentVolumeClaim:</p>
<pre><code>$ more nfs-client-pvc.yaml

kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  namespace: nfs 
  name: test-claim
  annotations:
    volume.beta.kubernetes.io/storage-class: "nfs-client"
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 1Mi
</code></pre>
<pre><code>$ kubectl apply -f nfs-client-pvc.yaml
</code></pre>
<p>Check the status (Bound is expected):</p>
<pre><code>$ kubectl get persistentvolumeclaim/test-claim -n nfs
NAME         STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
test-claim   Bound    pvc-e1cd4c78-7c7c-4280-b1e0-41c0473652d5   1Mi        RWX            nfs-client     24s
</code></pre>
<p><strong>4 - Create a simple pod to test if we can read/write out NFS Share:</strong></p>
<p>Create a pod using this yaml:</p>
<pre><code>apiVersion: v1
kind: Pod
metadata:
  name: pod0
  labels:
    env: test
  namespace: nfs  
spec:
  containers:
  - name: nginx
    image: nginx
    imagePullPolicy: IfNotPresent
    volumeMounts:
      - name: nfs-pvc
        mountPath: "/mnt"
  volumes:
    - name: nfs-pvc
      persistentVolumeClaim:
        claimName: test-claim
</code></pre>
<pre><code>$ kubectl apply -f pod.yaml
</code></pre>
<p>Now, let’s dig inside this pod:</p>
<pre><code>$ kubectl exec -ti -n nfs pod0 -- bash
</code></pre>
<p>Let’s list all mounted volumes on our pod:</p>
<pre><code>root@pod0:/# df -h
Filesystem                                                                                Size  Used Avail Use% Mounted on
overlay                                                                                   9.8G  6.1G  3.3G  66% /
tmpfs                                                                                      64M     0   64M   0% /dev
tmpfs                                                                                     7.4G     0  7.4G   0% /sys/fs/cgroup
kubemaster:/mnt/nfs_server_files/nfs-test-claim-pvc-4550f9f0-694d-46c9-9e4c-7172a3a64b12  9.8G  5.8G  3.6G  62% /mnt
/dev/sda1                                                                                 9.8G  6.1G  3.3G  66% /etc/hosts
shm                                                                                        64M     0   64M   0% /dev/shm
tmpfs                                                                                     7.4G   12K  7.4G   1% /run/secrets/kubernetes.io/serviceaccount
tmpfs                                                                                     7.4G     0  7.4G   0% /proc/acpi
tmpfs                                                                                     7.4G     0  7.4G   0% /sys/firmware
</code></pre>
<p>As we can see, we have a NFS volume mounted on /mnt. (Important to notice the path <code>kubemaster:/mnt/nfs_server_files/nfs-test-claim-pvc-4550f9f0-694d-46c9-9e4c-7172a3a64b12</code>)</p>
<p>Let’s check it:</p>
<pre><code>root@pod0:/# cd /mnt
root@pod0:/mnt# ls -la
total 8
drwxrwxrwx 2 nobody nogroup 4096 Nov  5 08:33 .
drwxr-xr-x 1 root   root    4096 Nov  5 08:38 ..
</code></pre>
<p>It’s empty. Let’s create some files:</p>
<pre><code>$ for i in 1 2 4 5 6; do touch file$i; done;
$ ls -l 
total 8
drwxrwxrwx 2 nobody nogroup 4096 Nov  5 08:58 .
drwxr-xr-x 1 root   root    4096 Nov  5 08:38 ..
-rw-r--r-- 1 nobody nogroup    0 Nov  5 08:58 file1
-rw-r--r-- 1 nobody nogroup    0 Nov  5 08:58 file2
-rw-r--r-- 1 nobody nogroup    0 Nov  5 08:58 file4
-rw-r--r-- 1 nobody nogroup    0 Nov  5 08:58 file5
-rw-r--r-- 1 nobody nogroup    0 Nov  5 08:58 file6
</code></pre>
<p>Now let’s where are these files on our NFS Server (Master Node):</p>
<pre><code>$ cd /mnt/nfs_server_files
$ ls -l 
total 4
drwxrwxrwx 2 nobody nogroup 4096 Nov  5 09:11 nfs-test-claim-pvc-4550f9f0-694d-46c9-9e4c-7172a3a64b12
$ cd nfs-test-claim-pvc-4550f9f0-694d-46c9-9e4c-7172a3a64b12/
$ ls -l 
total 0
-rw-r--r-- 1 nobody nogroup 0 Nov  5 09:11 file1
-rw-r--r-- 1 nobody nogroup 0 Nov  5 09:11 file2
-rw-r--r-- 1 nobody nogroup 0 Nov  5 09:11 file4
-rw-r--r-- 1 nobody nogroup 0 Nov  5 09:11 file5
-rw-r--r-- 1 nobody nogroup 0 Nov  5 09:11 file6
</code></pre>
<p>And here are the files we just created inside our pod!</p>

